#!/usr/bin/env python2.7

#TO FIX: Make split reads work for 25 and 26 bp gene specific regions

import argparse, subprocess, os, gzip, logging, time, collections, HTSeq
from itertools import izip_longest
from collections import defaultdict
from multiprocessing import Pool

logging.basicConfig(filename='MPE-seq.log', filemode='w', format='%(asctime)s %(message)s', datefmt='%Y-%m-%d %H:%M:%S', level=logging.INFO)

def main(args):

	start_time = time.time()

	samples = []
	summary = {}

	setup(args)

	targets, intron_set, fiveSS, threeSS = readTargetFeatures(args.target_intervals)

	p = Pool(8)
	p.map(processSample, ((sample.split('/')[-1], args, targets, intron_set, fiveSS, threeSS, summary) for sample in args.input_files))
	p.close()
	p.join()
	
	#for i in args.input_files:
	#	sample = i.split('/')[-1]
	#	samples.append(sample)
	#	processSample((sample, args, targets, intron_set, fiveSS, threeSS, summary))

	#printSummary(samples, summary)

	logging.info('Completed in %ds' % (time.time() - start_time))

def setup(args):
	
	SI_summary = open('SI_summary.txt', 'w')
	SI_summary.write('Sample\tIntron\tMature\tPremature\n')
	SI_summary.close()

	Junction_summary = open('Junction_summary.txt', 'w')
	Junction_summary.write('Sample\tGene\tUpstream\tDownstream\tType\tCount\n')
	Junction_summary.close()

	logging.info('Using hisat index at %s' % (args.hisatIndex))

def readTargetFeatures(interval):
	logging.info('Reading intron ranges from %s' % (interval))
	intron_set = set()
	fiveSS = {}
	threeSS = {}
	targets = HTSeq.GenomicArrayOfSets('auto', stranded=False)
	for line in open(interval):
		fields = line.rstrip().split('\t')
		iv = HTSeq.GenomicInterval(fields[0], int(fields[1])-1, int(fields[2]), fields[4])
		targets[iv] += fields[3]
		intron_set.add(fields[3])
		if fields[4] == '+':
			fiveSS[(fields[0], int(fields[1]), fields[4])] = tuple(fields[3].split(';'))
			threeSS[(fields[0], int(fields[2]), fields[4])] = tuple(fields[3].split(';'))
		else:
			fiveSS[(fields[0], int(fields[2]), fields[4])] = tuple(fields[3].split(';'))
			threeSS[(fields[0], int(fields[1]), fields[4])] = tuple(fields[3].split(';'))

	return targets, intron_set, fiveSS, threeSS

def processSample(x):
	
	sample, args, targets, intron_set, fiveSS, threeSS, summary = x

	logging.info(' Processing %s' % (sample))
	sample_summary = {}

	# Create folder for sample
	if not os.path.exists(sample):
		os.makedirs(sample)

	# Trim Adapters
	trimAdapters(sample, summary)

	#Extract molecular counter and remove PCR duplicates
	if args.umi_deduplication:
		removePCRDuplicates_ExtractMolecularCounter(sample, args.moleCountLen, summary)
	else:
		extractMolecularCounter(sample, args.moleCountLen, summary)

	# Alignment
	align(sample, args.hisatIndex, summary)

	# Count features
	feature_count(sample, targets, intron_set, fiveSS, threeSS, summary)

	logging.info(' Completed %s' % (sample))

def trimAdapters(sample, summary):
	cmd = 'fastp -i ../fastq/%s_R1.fastq.gz -I ../fastq/%s_R2.fastq.gz -o %s/%s_trim_R1.fastq.gz -O %s/%s_trim_R2.fastq.gz -w 1 --adapter_sequence CTGTCTCTTATACACATCT --adapter_sequence_r2 CTGTCTCTTATACACATCT --html %s/%s_trim_report.html --json %s/%s_trim_report.json' % (sample, sample, sample, sample, sample, sample, sample, sample, sample, sample)
	proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)
	(out, err) = proc.communicate()
	info = err.split('\n')

def extractMolecularCounter(sample, n, summary):

	numProcessed = 0
	toOut1 = []
	toOut2 = []

	out1 = gzip.open('%s/%s_mole_R1.fastq.gz' % (sample, sample) ,'wb')
	out2 = gzip.open('%s/%s_mole_R2.fastq.gz' % (sample, sample) ,'wb')

	with gzip.open('%s/%s_trim_R1.fastq.gz' % (sample, sample)) as i1, gzip.open('%s/%s_trim_R2.fastq.gz' % (sample, sample)) as i2:
		for line1, line2 in izip_longest(i1, i2):
			
			info1 = line1.rstrip().split(' ')[0]
			info2 = line2.rstrip().split(' ')[0]

			seq1 = next(i1).rstrip()
			extra1 = next(i1).rstrip()
			quality1 = next(i1).rstrip()

			seq2 = next(i2).rstrip()
			extra2 = next(i2).rstrip()
			quality2 = next(i2).rstrip()
 
			if info1 != info2:
				print 'Error: %s does not match %s' % (info1, info2)
			
			if len(seq1) > 13:
				toOut1.append('%s;%s\n%s\n%s\n%s\n' % (info1, seq1[:n], seq1[n:], extra1, quality1[n:]))
				toOut2.append('%s;%s\n%s\n%s\n%s\n' % (info2, seq1[:n], seq2, extra2, quality2))

			if numProcessed % 1000000 == 0:
				out1.write(''.join(toOut1))
				out2.write(''.join(toOut2))
				toOut1 = []
				toOut2 = []

			numProcessed += 1

	out1.write(''.join(toOut1))
	out2.write(''.join(toOut2))
	out1.close()
	out2.close()

	summary[(sample, 'unique')] = numProcessed

def removePCRDuplicates_ExtractMolecularCounter(sample, n, summary):

	occured = set()
	numProcessed = 0
	numUnique = 0
	out1 = []
	out2 = []
	s = {}


	with gzip.open('%s/%s_trim_R1.fastq.gz' % (sample, sample)) as i1, gzip.open('%s/%s_trim_R2.fastq.gz' % (sample, sample)) as i2:
		for line1, line2 in izip_longest(i1, i2):
			
			info1 = line1.rstrip().split(' ')[0]
			info2 = line2.rstrip().split(' ')[0]

			seq1 = next(i1).rstrip()
			extra1 = next(i1).rstrip()
			quality1 = next(i1).rstrip()

			seq2 = next(i2).rstrip()
			extra2 = next(i2).rstrip()
			quality2 = next(i2).rstrip()
 
			if info1 != info2:
				print 'Error: %s does not match %s' % (info1, info2)

			if (seq1, seq2) not in occured:
				out1.append('%s;%s\n%s\n%s\n%s\n' % (info1, seq1[:n], seq1[n:], extra1, quality1[n:]))
				out2.append('%s;%s\n%s\n%s\n%s\n' % (info2, seq1[:n], seq2, extra2, quality2))
				numUnique += 1
				occured.add((seq1, seq2))

			if numProcessed % 1000000 == 0:
				logging.info('\t\tProcessed %d Reads in %ds' % (numProcessed, time.time()-local_start_time))

			numProcessed += 1

	with gzip.open('%s/%s_mole_R1.fastq.gz' % (sample, sample) ,'wb') as out:
		out.write(''.join(out1))

	with gzip.open('%s/%s_mole_R2.fastq.gz' % (sample, sample) , 'wb') as out:
		out.write(''.join(out2))

	summary[(sample, 'unique')] = numUnique

def align(sample, index, summary):
	cmd = 'hisat2 -p 1 --phred33 --new-summary --max-intronlen 1000 -x %s -1 %s/%s_mole_R1.fastq.gz -2 %s/%s_mole_R2.fastq.gz | samtools view -bh - | samtools sort - -o %s/%s.bam' % (index, sample, sample, sample, sample, sample, sample)
	proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)
	(out, err) = proc.communicate()

	with open('%s/%s_alignment.log' % (sample, sample), 'w') as alignOut:
		alignOut.write(err)
	info = err.split('\n')

def feature_count(sample, targets, intron_set, fiveSS, threeSS, summary):

	SI_counts = defaultdict(int)
	junction_counts = defaultdict(int)
	
	for alignment in HTSeq.BAM_Reader('%s/%s.bam' % (sample, sample)):

		if alignment.pe_which == 'first' and alignment.aligned and alignment.aQual > 5 and alignment.iv.chrom != 'MT' and alignment.iv.chrom != 'AB325691' and alignment.iv.chrom != 'MTR':

			introns = set()
			junctions = set()

			for i, cigop in enumerate(alignment.cigar):
				if cigop.type == 'M':
					for iv, val in targets[cigop.ref_iv].steps():
						introns |= val
				elif cigop.type == 'N':
					if alignment.cigar[i-1].type =='M' and alignment.cigar[i-1].size > 3 and alignment.cigar[i+1].type =='M' and alignment.cigar[i+1].size > 3:
						for iv, val in targets[cigop.ref_iv].steps():
							junctions |= val

						chrom = cigop.ref_iv.chrom
						if cigop.ref_iv.strand == '+':
							first = cigop.ref_iv.end
							second = cigop.ref_iv.start + 1
							strand = '-'
						else:
							first = cigop.ref_iv.start + 1
							second = cigop.ref_iv.end
							strand = '+'

						if (chrom, first, strand) in fiveSS and (chrom, second, strand) in threeSS:
							up = fiveSS[chrom, first, strand]
							down = threeSS[chrom, second, strand]
							if up[0] == down[0]:
								if up[1] == down[1]:
									junction_counts[(sample, up[0], int(up[1]), int(down[1])+1, "Constituitive")] += 1
								else:
									junction_counts[(sample, up[0], int(up[1]), int(down[1])+1, "Exon Skipping")] += 1
						elif (chrom, first, strand) in fiveSS:
							junction_counts[(sample, up[0], int(up[1]), int(down[1])+1, "Alternative 3'")] += 1
						elif (chrom, second, strand) in threeSS:
							junction_counts[(sample, up[0], int(up[1]), int(down[1])+1, "Alternative 5'")] += 1

			candidate_genes = set()
			for i in introns:
				candidate_genes.add(i)
			for i in junctions:
				candidate_genes.add(i)

			if len(candidate_genes) == 1:
				for i in junctions:
					SI_counts[('mature', i)] += 1
				for i in introns:
					SI_counts[('premature', i)] +=1

	with open('%s/%s_counts.txt' % (sample, sample), 'w') as out:
		out.write('Intron\tMature\tPremature\n')
		for intron in sorted(intron_set):
			out.write('%s\t%d\t%d\n' % (intron, SI_counts[('mature', intron)], SI_counts[('premature', intron)]))

	with open('SI_summary.txt', 'a') as out:
		for intron in sorted(intron_set):
			out.write('%s\t%s\t%d\t%d\n' % (sample, intron, SI_counts[('mature', intron)], SI_counts[('premature', intron)]))

	with open('%s/%s_junctionCounts.txt' % (sample, sample), 'w') as out:
		out.write('Gene\tUpstream\tDownstream\tType\tCount\n')
		for junc in sorted(junction_counts):
			out.write('%s\t%d\t%d\t%s\t%d\n' % (junc[1], junc[2], junc[3], junc[4], junction_counts[junc]))

	with open('Junction_summary.txt', 'a') as out:
		for junc in sorted(junction_counts):
			out.write('%s\t%s\t%d\t%d\t%s\t%d\n' % (sample, junc[1], junc[2], junc[3], junc[4], junction_counts[junc]))

def printSummary(samples, summary):
	categories = ['read1_pre','base1_pre','read1_post','base1_post','read2_pre','base2_pre','read2_post','base2_post','passed','fail_low_quality','fail_N','fail_short','reads_trimmed','bases_trimmed','duplication','insert_size', 'unique', 'total_pairs_umi', '0_concordant_umi', '1_concordant_umi', '>1_concordant_umi', '1_discordant_umi', 'unpaired_umi', '0_unpaired_umi', '1_unpaired_umi', '>1_unpaired_umi', 'overall_alignment_rate_umi']
	with open('MPE_summary.txt', 'w') as out:
		out.write('Sample\t%s\n' % ('\t'.join(categories)))
		for sample in samples:
			out.write('%s\t%s\n' % (sample, '\t'.join([str(summary[(sample, category)]) for category in categories])))

def parseArguments():
	parser = argparse.ArgumentParser(prog="MPE_PipeLine_PE", description='', usage='%(prog)s [options]')
	required = parser.add_argument_group('required arguments')
	required.add_argument('-i', '--input_files', nargs='+', required=True, help=' Basename of files to run. (fastq.gz)', metavar='', dest='input_files')
	mole = parser.add_argument_group('Extracting Molecular Counter Options')
	duplicate = parser.add_argument_group('UMI Deduplication Options')
	alignment = parser.add_argument_group('Alignment Options')
	target_count = parser.add_argument_group('Target Counting Options')
	mole.add_argument('-m', '--umi_length', type=int, default=7, help=" Length of Molecular Counter at 5' end of Read 1. (Default: 7)", metavar='', dest='moleCountLen')
	duplicate.add_argument('-d', '--umi_deduplication', type=bool, default=False, help=' Perform UMI deduplication. (Default: False)', metavar='', dest='umi_deduplication')
	alignment.add_argument('--hisat_index', default='~/Lab/Genomes/pombe/hisat/sp_hisatIndex_v2.30', help=' Location of hisat index files.', dest='hisatIndex')
	target_count.add_argument('--target_intervals', default='/home/zdwyer/Lab/Genomes/pombe/sp_mpe_subset_intronRanges_v2.30.bed', help=' File containing intervals for which to count reads.', dest='target_intervals')

	return parser.parse_args()

args = parseArguments()

main(args)